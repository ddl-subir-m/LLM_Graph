{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac31e45d-3b1a-442e-b243-f7724f7960e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j yfiles_jupyter_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f5ad2f4-ba75-4e52-8320-ec10faa5e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PubMedLoader\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52edd244-9c0d-4252-9a3e-210aca9cdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from environment\n",
    "NEO4J_URI = \"neo4j+s://4205a689.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"ptU0r78H6sHohS0sptyympBAdlzRf93kkxVUaBl-v8g\"\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
    "\n",
    "graph = Neo4jGraph(url=NEO4J_URI,password=NEO4J_PASSWORD, database=NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ff81d04-227a-4f75-aa61-2e94df8192dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PubMedLoader(\"caffeine\", load_max_docs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83792515-e21d-4e1d-bb26-07922e91b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e51cc4cb-51cc-483e-9688-bf738855ea44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': '38516974',\n",
       " 'Title': 'Effect of caffeine on the aggregation of amyloid-β-A 3D RISM study.',\n",
       " 'Published': '--',\n",
       " 'Copyright Information': '© 2024 Author(s). Published under an exclusive license by AIP Publishing.'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51b8cd0d-99df-495d-9dd7-5a82c0812417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alzheimer's disease is a detrimental neurological disorder caused by the formation of amyloid fibrils due to the aggregation of amyloid-β peptide. The primary therapeutic approaches for treating Alzheimer's disease are targeted to prevent this amyloid fibril formation using potential inhibitor molecules. The discovery of such inhibitor molecules poses a formidable challenge to the design of anti-amyloid drugs. This study investigates the effect of caffeine on dimer formation of the full-length amyloid-β using a combined approach of all-atom, explicit water molecular dynamics simulations and the three-dimensional reference interaction site model theory. The change in the hydration free energy of amyloid-β dimer, with and without the inhibitor molecules, is calculated with respect to the monomeric amyloid-β, where the hydration free energy is decomposed into energetic and entropic components, respectively. Dimerization is accompanied by a positive change in the partial molar volume. Dimer formation is spontaneous, which implies a decrease in the hydration free energy. However, a reverse trend is observed for the dimer with inhibitor molecules. It is observed that the negatively charged residues primarily contribute for the formation of the amyloid-β dimer. A residue-wise decomposition reveals that hydration/dehydration of the side-chain atoms of the charged amino acid residues primarily contribute to dimerization.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbcf65d1-b1cd-4426-b32b-be2dabe4d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20068dc4-d540-46b2-98d7-2a422e6abbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs.graph_document import (\n",
    "    Node as BaseNode,\n",
    "    Relationship as BaseRelationship,\n",
    "    GraphDocument,\n",
    ")\n",
    "from langchain.schema import Document\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.pydantic_v1 import Field, BaseModel\n",
    "\n",
    "class Property(BaseModel):\n",
    "  \"\"\"A single property consisting of key and value\"\"\"\n",
    "  key: str = Field(..., description=\"key\")\n",
    "  value: str = Field(..., description=\"value\")\n",
    "\n",
    "class Node(BaseNode):\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of node properties\")\n",
    "\n",
    "class Relationship(BaseRelationship):\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of relationship properties\"\n",
    "    )\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Generate a knowledge graph with entities and relationships.\"\"\"\n",
    "    nodes: List[Node] = Field(\n",
    "        ..., description=\"List of nodes in the knowledge graph\")\n",
    "    rels: List[Relationship] = Field(\n",
    "        ..., description=\"List of relationships in the knowledge graph\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67596dec-bb5e-4cf9-863d-948def31f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_property_key(s: str) -> str:\n",
    "    words = s.split()\n",
    "    if not words:\n",
    "        return s\n",
    "    first_word = words[0].lower()\n",
    "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
    "    return \"\".join([first_word] + capitalized_words)\n",
    "\n",
    "def props_to_dict(props) -> dict:\n",
    "    \"\"\"Convert properties to a dictionary.\"\"\"\n",
    "    properties = {}\n",
    "    if not props:\n",
    "      return properties\n",
    "    for p in props:\n",
    "        properties[format_property_key(p.key)] = p.value\n",
    "    return properties\n",
    "\n",
    "def map_to_base_node(node: Node) -> BaseNode:\n",
    "    \"\"\"Map the KnowledgeGraph Node to the base Node.\"\"\"\n",
    "    properties = props_to_dict(node.properties) if node.properties else {}\n",
    "    # Add name property for better Cypher statement generation\n",
    "    properties[\"name\"] = node.id.title()\n",
    "    return BaseNode(\n",
    "        id=node.id.title(), type=node.type.capitalize(), properties=properties\n",
    "    )\n",
    "\n",
    "\n",
    "def map_to_base_relationship(rel: Relationship) -> BaseRelationship:\n",
    "    \"\"\"Map the KnowledgeGraph Relationship to the base Relationship.\"\"\"\n",
    "    source = map_to_base_node(rel.source)\n",
    "    target = map_to_base_node(rel.target)\n",
    "    properties = props_to_dict(rel.properties) if rel.properties else {}\n",
    "    return BaseRelationship(\n",
    "        source=source, target=target, type=rel.type, properties=properties\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a7349908-41ad-4ccd-846f-5f1521bed309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "\n",
    "def get_extraction_chain(\n",
    "    allowed_nodes: Optional[List[str]] = None,\n",
    "    allowed_rels: Optional[List[str]] = None\n",
    "    ):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\n",
    "          \"system\",\n",
    "          f\"\"\"# Knowledge Graph Instructions\n",
    "## 1. Overview\n",
    "You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\n",
    "- **Nodes** represent entities and concepts similar to Wikipedia entries. Restrict the total number of unique entities and concepts to 10 to maintain focus and clarity.\n",
    "- The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible to a broad audience. The structure of the graph should be straightforward.\n",
    "\n",
    "## 2. Labeling Nodes\n",
    "- **Consistency**: Ensure you use basic or elementary types for node labels.\n",
    "  - For example, when you identify an entity representing a person, always label it as **\"person\"**. Avoid using more specific terms like \"researcher\" or \"participant\" in the context of medical studies.\n",
    "- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text, such as the name of a person like \"Joe\" or computer science terms like \"algorithm\".\n",
    "\n",
    "## 3. Handling Numerical Data and Dates\n",
    "- Numerical data, like measurements of REE or blood pressure, should be incorporated as attributes or properties of the respective nodes.\n",
    "- **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.\n",
    "- **Property Format**: Properties must be in a key-value format, with keys in camelCase\n",
    "- **Quotation Marks**: Never use escaped single or double quotes within property values.\n",
    "\n",
    "## 4. Coreference Resolution\n",
    "If an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),\n",
    "always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\n",
    "Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\n",
    "\n",
    "## 5. Strict Compliance\n",
    "Adherence to these guidelines is mandatory. Non-compliance will result in the discontinuation of the algorithm's application. Ensuring accuracy, consistency, and clarity in the knowledge graph is paramount for it to be a reliable and valuable medical resource.\n",
    "\n",
    "          \"\"\"),\n",
    "            (\"human\", \"Use the given format to extract information from the following input: {input}\"),\n",
    "            (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
    "        ])\n",
    "    return create_structured_output_chain(KnowledgeGraph, llm, prompt, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e121b3e6-959d-48a2-8935-553583e50f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_store_graph(\n",
    "    document: Document,\n",
    "    nodes:Optional[List[str]] = None,\n",
    "    rels:Optional[List[str]]=None) -> None:\n",
    "    # Extract graph data using OpenAI functions\n",
    "    extract_chain = get_extraction_chain(nodes, rels)\n",
    "    data = extract_chain.invoke(document.page_content)['function']\n",
    "    # Construct a graph document\n",
    "    graph_document = GraphDocument(\n",
    "      nodes = [map_to_base_node(node) for node in data.nodes],\n",
    "      relationships = [map_to_base_relationship(rel) for rel in data.rels],\n",
    "      source = document\n",
    "    )\n",
    "    # Store information into a graph\n",
    "    graph.add_graph_documents([graph_document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9af67-fa35-4223-a612-7f9cfd3924ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "allowed_nodes = [\"Person\", \"Company\", \"Location\", \"Event\", \"Movie\", \"Service\", \"Award\"]\n",
    "\n",
    "for i, d in tqdm(enumerate(documents), total=len(documents)):\n",
    "    extract_and_store_graph(d, allowed_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f2a135e-a493-4c07-bc96-5ee3428e8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the knowledge graph in a RAG application\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "graph.refresh_schema()\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    graph=graph,\n",
    "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    validate_cypher=True, # Validate relationship directions\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3daf8f1-f056-4f6b-b53d-c60e1f035a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_chain.invoke({\"query\": \"What is caffeine?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c86299c-2842-41cf-bf0e-c6a665ee9243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  arxiv pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09944afb-3f0c-4357-951b-d2e5eb509395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2047be0-733d-4753-a90f-77826265dda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = ArxivLoader(query=\"1706.03762\", load_max_docs=2).load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a45f3e5-af02-45f4-bef3-d3f560368fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2023-08-02',\n",
       " 'Title': 'Attention Is All You Need',\n",
       " 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin',\n",
       " 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata  # meta-information of the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf68fd-127c-436e-8f08-18e4c383c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0].page_content # all pages of the Document content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c983a3ec-919d-4fbb-8247-d2f4711e001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# allowed_nodes = [\"Person\", \"Metric\", \"Mechanism\", \"Task\", \"Algorithm\"]\n",
    "\n",
    "for i, d in tqdm(enumerate(documents), total=len(documents)):\n",
    "    # extract_and_store_graph(d, allowed_nodes)\n",
    "    extract_and_store_graph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b06062-5b42-40fe-8d76-6d33add9fd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
